{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'0.21.0'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 3 Dict\n",
    "- First 3 are in form inps[id->(tx_id,output_id)]\n",
    "- The remaining dictionaries are inps_by_tx being tx_id->[inp_id]* where inps[inp_id][0] = tx_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "inps = {}\n",
    "outs = {}\n",
    "txs = {}\n",
    "\n",
    "def readIntoDict(d,f_name,key_index):\n",
    "    with open(f_name,'r') as f:\n",
    "        for l in f:\n",
    "            arr=l.split(',')\n",
    "            k = int(arr[key_index])\n",
    "            del arr[key_index]\n",
    "            d[k] = tuple(map(int,arr))\n",
    "readIntoDict(inps,'inputs.csv',0)\n",
    "readIntoDict(outs,'outputs.csv',0)\n",
    "readIntoDict(txs,'transactions.csv',0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inps_by_tx = defaultdict(list)\n",
    "inps_by_out = defaultdict(list)\n",
    "outs_by_tx = defaultdict(list)\n",
    "txs_by_blk = defaultdict(list)\n",
    "\n",
    "def groupByFirstColumn(dict_new,dict_id,i=0):\n",
    "    for k,v in dict_id.iteritems():\n",
    "          dict_new[v[i]].append(k)\n",
    "groupByFirstColumn(inps_by_tx,inps)\n",
    "groupByFirstColumn(inps_by_out,inps,i=1)\n",
    "groupByFirstColumn(outs_by_tx,outs)\n",
    "groupByFirstColumn(txs_by_blk,txs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Validty Checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Checker(object):\n",
    "    def __init__(self):\n",
    "        self.txo = set() #outputs that is spent\n",
    "    \n",
    "    def checkInputs(s,t_id,block_id):\n",
    "        tx_inputs = [inps[i][-1] for i in inps_by_tx[t_id]]\n",
    "        tx_outputs = [o for o in outs_by_tx[t_id]]\n",
    "        if len(set(tx_inputs) & set(tx_outputs) ) != 0:\n",
    "            print 'ERROR:Output transaction cannot be input'\n",
    "            print t_id,tx_inputs,tx_outputs,block_id\n",
    "            return False\n",
    "        if len(tx_inputs) != len(set(tx_inputs)): \n",
    "            print 'ERROR:There are two inputs pointing the same previous output'\n",
    "            print t_id,tx_inputs,block_id\n",
    "            return False\n",
    "        for o in tx_inputs:\n",
    "            if o not in outs:\n",
    "                print 'ERROR:Output script is not correct/doesn\\'t exists' \n",
    "                print t_id,tx_inputs,block_id\n",
    "                return False\n",
    "        for o in tx_outputs:\n",
    "            if outs[o][-1]<0:\n",
    "                print 'ERROR:Output value cant be less <0.'\n",
    "                print t_id,tx_outputs,block_id\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def checkBlockSum(s,tx_ids,block_id):\n",
    "        output_sum = input_sum = 0\n",
    "        curr_txo = set()\n",
    "        for t_id in tx_ids:\n",
    "            tx = txs[t_id]\n",
    "            if not s.checkInputs(t_id,block_id):\n",
    "                return False\n",
    "            tx_inputs = set(inps_by_tx[t_id])\n",
    "            tx_outputs = set(outs_by_tx[t_id])\n",
    "            for i_id in tx_inputs:\n",
    "                prev_out = inps[i_id][-1]\n",
    "                if prev_out in s.txo:\n",
    "                    print 'ERROR:output %d already used in another block. Called from i_id: %d,t_id: %d,block_id: %d' % (prev_out,i_id,t_id,block_id)\n",
    "                    return False\n",
    "                elif prev_out in curr_txo: #\n",
    "                    print 'ERROR:output %d already used within same block. Called from i_id: %d,t_id: %d,block_id: %d' % (prev_out,i_id,t_id,block_id)\n",
    "                    return False\n",
    "                else:\n",
    "                    input_sum += outs[prev_out][-1] #[1] for output_id, [-1] for value\n",
    "                    curr_txo.add(prev_out)\n",
    "                   \n",
    "            for o_id in tx_outputs:\n",
    "                    output_sum += outs[o_id][-1] #[-1] for value\n",
    "        if output_sum - input_sum > 5000000000:\n",
    "            print 'ERROR:Sum is not correct'\n",
    "            print output_sum - input_sum \n",
    "            return False\n",
    "        else:\n",
    "            s.txo.update(set([inps[i][-1] for i in tx_inputs]))\n",
    "            return True\n",
    "    def checkBlockBasic(s,block_id):\n",
    "        tx_ids = txs_by_blk[block_id]\n",
    "\n",
    "        if len(set(tx_ids)) != len(tx_ids):\n",
    "            print 'ERROR:Error multiple txs with same id!'\n",
    "            print tx_ids\n",
    "            return False\n",
    "        coinbase_txs = [i for i in tx_ids if txs[i][-1]==1]\n",
    "        if len(coinbase_txs) != 1:\n",
    "            print 'ERROR:Multiple coinbase transactions!'\n",
    "            print coinbase_txs\n",
    "            return False\n",
    "        coinbase_output_sum = sum([outs[o][-1] for o in (outs_by_tx[coinbase_txs[0]])])\n",
    "        if coinbase_output_sum < 5000000000:\n",
    "            print 'WARNING coinbase sum is less than the reward, wth might be wrong', coinbase_txs[0]\n",
    "        if inps_by_tx[coinbase_txs[0]]:\n",
    "            print 'ERROR:Coinbase transactions can\\'t have input!'\n",
    "            print 'tx: %d, b_id: %d ' % (coinbase_txs[0],block_id)\n",
    "            return False\n",
    "        if not s.checkBlockSum(tx_ids,block_id):\n",
    "            return False\n",
    "        return True\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:Sum is not correct\n",
      "5000000010\n",
      "11181 [11281, 11282]\n",
      "---------\n",
      "ERROR:output 7998 already used in another block. Called from i_id: 777,t_id: 12152,block_id: 12042\n",
      "12042 [12151, 12152]\n",
      "---------\n",
      "ERROR:Output script is not correct/doesn't exists\n",
      "15698 [265834] 15567\n",
      "15567 [15697, 15698]\n",
      "---------\n",
      "ERROR:There are two inputs pointing the same previous output\n",
      "30446 [21928, 21928] 30223\n",
      "30223 [30445, 30446]\n",
      "---------\n",
      "ERROR:Multiple coinbase transactions!\n",
      "[56851, 56853]\n",
      "52534 [56851, 56852, 56853]\n",
      "---------\n",
      "ERROR:output 65403 already used within same block. Called from i_id: 20183,t_id: 61845,block_id: 56565\n",
      "56565 [61841, 61842, 61843, 61844, 61845]\n",
      "---------\n",
      "ERROR:Sum is not correct\n",
      "5000000010\n",
      "72902 [100928, 100929]\n",
      "---------\n",
      "ERROR:Output value cant be less <0.\n",
      "105281 [123672] 75047\n",
      "75047 [105279, 105280, 105281]\n",
      "---------\n",
      "ERROR:Output transaction cannot be input\n",
      "137237 [156879, 166481] [166481, 166482] 88755\n",
      "88755 [137236, 137237]\n",
      "---------\n",
      "ERROR:output 249860 already used in another block. Called from i_id: 182185,t_id: 207365,block_id: 97423\n",
      "97423 [207356, 207357, 207358, 207359, 207360, 207361, 207362, 207363, 207364, 207365, 207366, 207367, 207368]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cc = Checker()\n",
    "invalidBlocks = set()\n",
    "for k in sorted(txs_by_blk.keys()):\n",
    "    if not cc.checkBlockBasic(k):\n",
    "        print k,txs_by_blk[k]\n",
    "        print '---------'\n",
    "        invalidBlocks.add(k)\n",
    "#print cc.txo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Coloring\n",
    "- What we want to do give colours to the each transaction, such that each related transaction should have the same -colour. \n",
    "- Then each colour groups would identify a person, we can "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GraphSearch(object):\n",
    "    def __init__(s,invalid_blocks=set()):\n",
    "        s.invalid_blocks = invalid_blocks\n",
    "        s.reset_search()\n",
    "    def reset_search(s):\n",
    "        s.seen_transactions = set()\n",
    "        for inv_b in s.invalid_blocks:\n",
    "            s.seen_transactions.update(txs_by_blk[inv_b])\n",
    "        s.utxo = set()\n",
    "    def dfs(s):\n",
    "        def dfs_helper(tx_id):\n",
    "            if tx_id not in s.seen_transactions:\n",
    "                #print tx_id\n",
    "                is_coinbase = txs[tx_id][1]\n",
    "                if is_coinbase:\n",
    "                    s.utxo.update(outs_by_tx[tx_id])\n",
    "                else:\n",
    "                    tx_inputs_outs = [inps[i][-1] for i in inps_by_tx[tx_id]]\n",
    "                    for tx_inp_out in tx_inputs_outs:\n",
    "                        dfs_helper(outs[tx_inp_out][0]) #tx of the output input points to. \n",
    "                        if tx_inp_out not in s.utxo:\n",
    "                            print 'ERROR input cannot be found, tx_id,tx_inp:%d,%d' %(tx_id,tx_inp_out)\n",
    "                    s.utxo.update(outs_by_tx[tx_id])\n",
    "                    s.utxo.difference_update(tx_inputs_outs)\n",
    "                s.seen_transactions.add(tx_id)\n",
    "                            \n",
    "        for tx_id in txs.keys():\n",
    "            dfs_helper(tx_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR input cannot be found, tx_id,tx_inp:114916,60228\n",
      "ERROR input cannot be found, tx_id,tx_inp:204751,249860\n",
      "ERROR input cannot be found, tx_id,tx_inp:207370,249869\n",
      "ERROR input cannot be found, tx_id,tx_inp:208063,249859\n",
      "ERROR input cannot be found, tx_id,tx_inp:208084,249863\n",
      "ERROR input cannot be found, tx_id,tx_inp:208477,249852\n",
      "ERROR input cannot be found, tx_id,tx_inp:208644,249853\n",
      "ERROR input cannot be found, tx_id,tx_inp:209913,249855\n",
      "ERROR input cannot be found, tx_id,tx_inp:211792,249857\n",
      "ERROR input cannot be found, tx_id,tx_inp:213613,249856\n"
     ]
    }
   ],
   "source": [
    "gs = GraphSearch(invalidBlocks)\n",
    "gs.dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71889\n"
     ]
    }
   ],
   "source": [
    "print len(sorted([(outs[a][-1],a) for a in gs.utxo],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EntityGroupingSearch(object):\n",
    "    def __init__(s,invalid_blocks=set()):\n",
    "        s.invalid_blocks = invalid_blocks\n",
    "        s.reset_search()\n",
    "    def reset_search(s):\n",
    "        s.txlabels = {}\n",
    "        #Prelabeling invalid tx's\n",
    "        for inv_b in s.invalid_blocks:\n",
    "            s.txlabels.update({tx:-1 for tx in txs_by_blk[inv_b]})\n",
    "        \n",
    "    def dfs(s):\n",
    "        def dfs_helper(tx_id,label_id):\n",
    "            if tx_id not in s.txlabels:\n",
    "                if len(outs_by_tx[tx_id]) == 1: #one owner!\n",
    "                    s.txlabels[tx_id] = label_id\n",
    "                    dfs_helper(outs[outs_by_tx[tx_id][0]][0],label_id)\n",
    "                    for i in inps_by_tx[tx_id]:\n",
    "                        dfs_helper(inps[i][0],label_id)\n",
    "                else:\n",
    "                    s.txlabels[tx_id] = 0                    \n",
    "        i = 0\n",
    "        for tx_id in txs.keys():\n",
    "            if tx_id not in s.txlabels:\n",
    "                i+=1\n",
    "                dfs_helper(tx_id,i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "egs = EntityGroupingSearch(invalidBlocks)\n",
    "egs.dfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursively matching public keys and outputs\n",
    "Whenever we process the output we merge it, if we seen it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "entities = defaultdict(list)\n",
    "pk_to_entity = {}\n",
    "for k,v in egs.txlabels.iteritems():\n",
    "    if v > 0:\n",
    "        prev_outs = [inps[i][-1] for i in inps_by_tx[k]]\n",
    "        for o in outs_by_tx[k] + prev_outs:\n",
    "            pk = outs[o][1]\n",
    "            if pk in pk_to_entity:\n",
    "                new_ent = pk_to_entity[pk]\n",
    "                if new_ent != v:\n",
    "                    if v in entities: # merge the current entity to the other\n",
    "                        for old_pk in entities[v]:\n",
    "                            pk_to_entity[old_pk] = new_ent\n",
    "                        entities[new_ent].extend(entities[v])\n",
    "                        del entities[v]\n",
    "                    v = new_ent\n",
    "            else:\n",
    "                entities[v].append(pk)\n",
    "                pk_to_entity[pk] = v\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasifying entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53738\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "entity_utxos = defaultdict(list)\n",
    "for o in gs.utxo:\n",
    "    if outs[o][1] in pk_to_entity:\n",
    "        entity_utxos[pk_to_entity[outs[o][1]]].append(o)\n",
    "print len(entity_utxos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_total_balances = {}\n",
    "for e,os in entity_utxos.iteritems():    \n",
    "    person_total_balances[e] = sum([outs[o][-1] for o in os])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Total Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98346739827397, 215565)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print sorted([(v,k) for k,v in person_total_balances.items()],reverse=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum publickey is 172 \n"
     ]
    }
   ],
   "source": [
    "print 'Minimum publickey is %d ' % min(entities[215565])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_pks = set(entities[215565])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500000000000, 139532)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(((o_res[-1],o_res[0]) for o_id,o_res in outs.items() if o_res[1] in my_pks))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264310\n"
     ]
    }
   ],
   "source": [
    "print len(outs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
